\documentclass[journal]{IEEEtran}

% Packages
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subfigure} % Keep for existing subfigure environments
\usepackage[colorlinks,linkcolor=red,anchorcolor=green,citecolor=blue]{hyperref}
\usepackage{orcidlink}

\usepackage{tikz}
\usetikzlibrary{positioning, shapes, arrows.meta, calc, fit, backgrounds}
\usetikzlibrary{decorations.pathreplacing, shapes.geometric}
\usetikzlibrary{shadows, patterns}
\usetikzlibrary{arrows}
\usetikzlibrary{backgrounds}
\usetikzlibrary{fadings}
\usetikzlibrary{decorations.pathmorphing}
\usetikzlibrary{clouds}


% Correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\begin{document}

% Paper title
\title{Dynamically Structured Manifold Clustering: A Framework for Multi-Modal Time Series}

% Author names and affiliations
\author{Author~Name,~\IEEEmembership{Member,~IEEE,}
        Second~Author,~\IEEEmembership{Member,~IEEE,}
        and~Third~Author,~\IEEEmembership{Senior~Member,~IEEE}
\thanks{Manuscript received Month DD, YYYY; revised Month DD, YYYY.}
\thanks{Author Name is with the Department of Computer Science, University Name, City, State ZIP, Country (e-mail: author@university.edu).}
\thanks{Second Author is with the Department of Electrical Engineering, University Name, City, State ZIP, Country (e-mail: second@university.edu).}
\thanks{Third Author is with the Department of Data Science, University Name, City, State ZIP, Country (e-mail: third@university.edu).}}

% Make the title area
\maketitle

\begin{abstract}
The clustering of multi-modal time series, such as household energy consumption correlated with weather data, presents substantial challenges in effectively fusing heterogeneous information and learning a discriminative representation space. Existing deep clustering methods often lack mechanisms for adaptively modeling the intricate interplay between modalities or for explicitly shaping the latent space to optimize cluster separability. To address these limitations, we introduce Dynamically Structured Manifold Clustering (DSMC), a novel end-to-end paradigm. DSMC reframes multi-modal clustering as learning a latent manifold whose geometric structure is actively and adaptively shaped during training by the characteristics of the input data and their inter-modal relationships. This dynamic structuring is realized through two core technical innovations: (1) a Gated Cross-Modal Attention mechanism that learns to dynamically regulate the influence of a secondary modality (e.g., weather) on the primary modality (e.g., energy load), thereby facilitating context-aware feature fusion; and (2) a novel Contrastive-Augmented clustering objective that leverages self-generated pseudo-labels to impose a geometrically robust and well-separated structure upon the learned manifold. Furthermore, we integrate a principled uncertainty quantification method using Monte Carlo Dropout, enabling risk-aware interpretation and application of the clustering results. Extensive experiments on real-world energy consumption datasets demonstrate that DSMC significantly outperforms a comprehensive suite of traditional and deep clustering baselines. Our results underscore that by adaptively fusing multi-modal data and explicitly engineering the latent space geometry, DSMC not only achieves superior clustering accuracy but also furnishes interpretable insights into the complex drivers of phenomena like household energy consumption patterns.
\end{abstract}

\begin{IEEEkeywords}
Deep Learning, Clustering, Multi-modal Learning, Time Series Analysis, Attention Mechanisms, Contrastive Learning, Energy Consumption, Uncertainty Quantification, Manifold Learning.
\end{IEEEkeywords}


\section{Introduction}
\IEEEPARstart{H}{ousehold} energy segmentation, the task of grouping consumers based on their electricity consumption patterns, has emerged as a cornerstone of modern smart grid management and energy policy design \cite{smart_grid_review}. By identifying distinct behavioral archetypes, utility providers can develop targeted demand response programs, optimize load forecasting, improve grid stability, and design more effective energy efficiency initiatives \cite{demand_response_survey}. However, the escalating complexity and volume of smart meter data, compounded by the necessity to account for external influential factors, pose significant challenges that traditional clustering algorithms are often ill-equipped to handle.

Early approaches to this problem predominantly relied on traditional clustering methods such as K-means \cite{kmeans_clustering} and spectral clustering \cite{spectral_clustering}, typically applied to handcrafted features derived from load profiles. While offering initial insights, these methods frequently fail to capture the intricate, non-linear temporal dependencies inherent in energy consumption data. The advent of deep learning has ushered in more potent representation learning techniques for clustering. Seminal works like Deep Embedded Clustering (DEC) \cite{deep_embedding_clustering_xie} demonstrated the efficacy of jointly learning feature representations and cluster assignments. Nevertheless, such models are typically designed for uni-modal data, thereby disregarding crucial external factors—most notably meteorological conditions—which are widely acknowledged as primary drivers of energy consumption.

The integration of multi-modal data, such as energy load shapes and corresponding weather time series, introduces a new stratum of complexity. These modalities are inherently heterogeneous, possessing disparate scales, statistical properties, and temporal dynamics. A critical challenge lies in fusing this information in a manner that is both meaningful and adaptive. For instance, the influence of ambient temperature on electricity usage is not static but varies significantly depending on the time of day, season, and the household's intrinsic consumption patterns. Moreover, for a clustering framework to be deployable in critical infrastructure applications, it must furnish not only cluster labels but also a principled measure of its own predictive uncertainty. Finally, for the derived insights to be actionable, the model should be interpretable, offering explanations of how external factors shape different consumption behaviors.

To address these multifaceted challenges, this paper introduces a new paradigm for multi-modal deep clustering, termed Dynamically Structured Manifold Clustering (DSMC). We reformulate the clustering task beyond a static partitioning problem, conceptualizing it as the learning of a latent manifold whose geometric structure is actively and adaptively shaped by the rich interplay of constituent data modalities throughout the training process. The DSMC framework is architected upon two core technical innovations: a Gated Cross-Modal Attention mechanism that facilitates adaptive, context-aware fusion between heterogeneous time series \cite{attention_is_all_you_need}, and a Contrastive-Augmented Clustering objective that explicitly imposes a discriminative metric structure on the learned manifold using principles from contrastive learning \cite{contrastive_learning_chen}. This approach empowers our model to learn not just the composition of clusters, but also how their formation is influenced by the dynamic relationship between, for example, energy usage and weather conditions. Extensive experiments demonstrate that DSMC significantly outperforms a range of traditional and deep clustering baselines on real-world energy consumption datasets. Our results indicate that by adaptively fusing multi-modal data and explicitly structuring the latent space, DSMC not only achieves superior clustering accuracy but also provides interpretable insights into the complex drivers of household energy consumption.

The main contributions of this work are:
\begin{enumerate}
    \item We propose the Dynamically Structured Manifold Clustering (DSMC) framework, a new end-to-end paradigm for multi-modal time series clustering. This framework uniquely integrates adaptive information fusion with explicit latent space structuring, where the manifold's geometry is dynamically refined during learning.
    \item We introduce a Gated Cross-Modal Attention mechanism specifically designed for heterogeneous time series. This mechanism learns to dynamically regulate the influence of a secondary modality (e.g., weather) on the primary modality's representation (e.g., energy load), thereby enhancing both clustering performance and model interpretability.
    \item We design a novel Contrastive-Augmented clustering objective that synergistically combines a DEC-style clustering loss with a supervised contrastive loss. This objective leverages self-generated pseudo-labels from the fused multi-modal representation to enforce a geometrically robust and well-separated structure on the latent manifold.
    \item We integrate a principled uncertainty quantification method using Monte Carlo Dropout \cite{mc_dropout_gal}, enabling risk-aware application and interpretation of the clustering results, which is crucial for real-world deployment.
\end{enumerate}

The remainder of this paper is structured as follows. Section II reviews related work in deep clustering, multi-modal learning, and contrastive representation learning. Section III details the proposed DSMC framework, elaborating on its novel fusion and optimization mechanisms. Section IV describes the experimental setup, datasets, and evaluation metrics. Section V presents our quantitative and qualitative results, including ablation studies and interpretability analysis. Finally, Section VI concludes the paper and outlines directions for future research.

\section{Related Work}
Our work is situated at the confluence of several key research areas: deep clustering, multi-modal learning with attention mechanisms, contrastive representation learning, and uncertainty quantification in deep models. We review pertinent literature in these domains and delineate how DSMC synthesizes and extends existing research.

\subsection{Deep Clustering}
Traditional clustering algorithms, such as K-means \cite{kmeans_clustering} and spectral clustering \cite{spectral_clustering}, operate on fixed, often manually engineered, feature representations. Consequently, their performance is heavily contingent upon the quality of these input features. Deep clustering has emerged to overcome this limitation by jointly learning feature representations and cluster assignments within a unified end-to-end framework.

Early deep clustering approaches often involved a sequential two-step process: first, an autoencoder (AE) or a variational autoencoder (VAE) is trained to learn a low-dimensional embedding of the data \cite{autoencoder_representation_learning}; subsequently, a traditional clustering algorithm is applied to this learned embedding. A significant advancement was Deep Embedded Clustering (DEC) \cite{deep_embedding_clustering_xie}, which introduced a clustering-oriented loss to simultaneously optimize the embeddings and refine cluster assignments. This seminal work spurred a lineage of related methods focusing on alternative clustering loss functions, network architectures \cite{improved_dec}, or reformulations of the clustering problem, such as Deep Self-Evolution Clustering (DSEC), which treats clustering as a binary pairwise classification task \cite{dsec_chang_tpami}.
Despite their power, the vast majority of these methods are designed for uni-modal data and lack inherent mechanisms for integrating information from multiple, heterogeneous sources, a primary challenge addressed by our work.

\subsection{Multi-Modal Learning and Fusion}
Multi-modal deep learning endeavors to construct models capable of processing and relating information from diverse data sources \cite{multi_modal_deep_learning_survey}. A central challenge in this domain is information fusion. Elementary approaches include early fusion, where raw features from different modalities are concatenated prior to model input, and late fusion, where uni-modal models are trained independently and their predictions are combined at the decision level. These methods, however, often fall short of capturing the complex, non-linear interactions between modalities.

More sophisticated techniques concentrate on learning a joint multi-modal representation. The advent of attention mechanisms, particularly the Transformer architecture \cite{attention_is_all_you_need}, has significantly advanced multi-modal fusion. Cross-modal attention enables a model to dynamically weigh features from one modality based on their relevance to another, providing a potent tool for learning inter-modal dependencies \cite{cross_modal_attention_survey}. Such techniques have achieved state-of-the-art results in domains like visual question answering and image-text retrieval. However, their application to the clustering of multi-modal time series, where temporal alignment and dynamic influence are critical, remains comparatively underexplored. Our DSMC framework addresses this gap by proposing a Gated Cross-Modal Attention mechanism specifically tailored for fusing heterogeneous time series like energy load and weather data, focusing on adaptive influence regulation.

\subsection{Contrastive Learning for Clustering}
Contrastive learning has recently risen as a dominant paradigm in self-supervised representation learning \cite{contrastive_learning_chen}. Its core tenet is to learn a representation space wherein embeddings of semantically similar ("positive") samples are attracted, while embeddings of dissimilar ("negative") samples are repelled. This principle has been effectively adapted for deep clustering.

Several recent studies have incorporated contrastive objectives into the clustering process. Some methods employ data augmentation to generate positive pairs for each anchor point, treating all other points as negatives \cite{contrastive_clustering_li}. Others have devised more refined strategies for selecting positive and negative pairs based on the model's evolving predictions, integrating contrastive learning into a self-training or pseudo-labeling loop. These methods have demonstrated that explicitly structuring the latent space with a contrastive objective often leads to more robust and well-separated clusters than relying solely on reconstruction or clustering-guidance losses. Our DSMC framework builds upon this insight. While contrastive learning has been applied to multi-modal representation learning, its specific integration into a multi-modal deep clustering objective that uses pseudo-labels generated from the fused representation to actively structure the manifold for improved cluster separation represents a novel combination. We posit that this particular synergy is key to achieving the performance gains observed.

\subsection{Positioning Our Work}
The DSMC framework synthesizes and extends these distinct research threads. Unlike most traditional deep clustering methods, it is inherently designed for multi-modal inputs. In contrast to generic multi-modal fusion techniques, its Gated Cross-Modal Attention is specifically engineered for the dynamic interplay characteristic of time series data, such as energy load and weather. Furthermore, distinct from many contrastive clustering methods that operate on uni-modal data or use augmentation-based positives, DSMC applies its contrastive objective to a fused multi-modal representation and integrates this objective into a joint optimization framework with a DEC-style clustering loss that provides the supervisory signal (pseudo-labels) for the contrastive component. By amalgamating these elements, DSMC offers a novel, principled solution to the challenging problem of multi-modal time series clustering, emphasizing the adaptive learning of a geometrically optimized manifold.

\section{Methodology: Dynamically Structured Manifold Clustering}
This paper introduces Dynamically Structured Manifold Clustering (DSMC), a framework conceived to address the intricacies of multi-modal time series clustering. DSMC advances beyond the conventional view of clustering as a static partitioning task, reformulating it as the learning of a latent manifold $\mathcal{Z} \subset \mathbb{R}^d$. The defining characteristic of DSMC is that the geometric structure of $\mathcal{Z}$ is not merely discovered but is actively and adaptively shaped throughout the learning process, influenced by the complex interactions between the constituent data modalities. This ``dynamic structuring" is realized by the synergistic operation of two core technical innovations within a unified end-to-end architecture: (1) a Gated Cross-Modal Attention mechanism that facilitates adaptive, context-aware fusion between heterogeneous time series, and (2) a Contrastive-Augmented Clustering objective that explicitly imposes a discriminative metric structure upon the learned manifold.

Let $(\mathbf{x}_i^{(p)}, \mathbf{x}_i^{(s)})$ denote a pair of multi-modal time series for the $i$-th sample, where $\mathbf{x}_i^{(p)} \in \mathbb{R}^{T \times D_p}$ is the primary modality (e.g., energy load) and $\mathbf{x}_i^{(s)} \in \mathbb{R}^{T \times D_s}$ is the secondary modality (e.g., weather data), with $T$ time steps and $D_p, D_s$ features, respectively. The DSMC framework aims to learn a mapping $g_\theta: (\mathbf{x}^{(p)}, \mathbf{x}^{(s)}) \mapsto \mathbf{z} \in \mathcal{Z}$, where $\mathbf{z}$ is the embedding in the $d$-dimensional latent manifold. This mapping is optimized via a composite objective function:
\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{rec}} + \lambda \mathcal{L}_{\text{cluster}} + \gamma \mathcal{L}_{\text{con}}
\label{eq:total_loss_revised}
\end{equation}
Here, $\mathcal{L}_{\text{rec}}$ is a reconstruction loss, typically applied to the primary modality, ensuring that the learned embeddings retain essential information. $\mathcal{L}_{\text{cluster}}$ is a clustering-specific loss (e.g., DEC-style) that promotes the formation of distinct cluster structures. $\mathcal{L}_{\text{con}}$ is a contrastive loss that further refines the manifold's geometry by enforcing intra-cluster compactness and inter-cluster separation. The hyperparameters $\lambda > 0$ and $\gamma > 0$ control the relative importance of these components. The interplay is crucial: $\mathcal{L}_{\text{rec}}$ initializes a meaningful representation space; $\mathcal{L}_{\text{cluster}}$ provides a self-supervisory signal by generating refined target distributions (pseudo-labels); and $\mathcal{L}_{\text{con}}$ leverages these pseudo-labels to explicitly engineer a robust geometric structure on the manifold. The framework is typically trained in two stages: pre-training using $\mathcal{L}_{\text{rec}}$ to establish a stable initial manifold, followed by joint optimization of all three loss terms.


\begin{figure*}[ht]
\centering
\resizebox{\textwidth}{!}{%
\begin{tikzpicture}[
    node distance=2.6cm and 2.7cm,
    >=latex,
    thick,
    every node/.style={font=\footnotesize, align=center},
    scale=0.97, every node/.append style={scale=0.97}
]

% Inputs
\node (x_p) [draw, rounded corners, minimum width=2.5cm, minimum height=0.8cm, fill=orange!15] {Primary Modality\\[-1ex] $x^{(p)}$\\(Load Time Series)};
\node (x_s) [below=1.2cm of x_p, draw, rounded corners, minimum width=2.5cm, minimum height=0.8cm, fill=blue!15] {Secondary Modality\\[-1ex] $x^{(s)}$\\(Weather Time Series)};

% Encoders
\node (enc_p) [right=of x_p, draw, rounded corners, minimum width=2.5cm, minimum height=0.8cm, fill=orange!5] {Primary Encoder\\[-1ex] (1D Dilated CNNs)\\$H^{(p)}$};
\node (enc_s) [right=of x_s, draw, rounded corners, minimum width=2.5cm, minimum height=0.8cm, fill=blue!5] {Secondary Encoder\\[-1ex] (1D Dilated CNNs)\\$H^{(s)}$};

% Attention & Gate
\node (attn) [right=2.2cm of $(enc_p)!0.5!(enc_s)$, draw, thick, rounded corners, minimum width=4.1cm, minimum height=2.7cm, fill=purple!10] {
    \textbf{Gated Cross-Modal Attention}\\[0.2ex]
    \begin{minipage}{3.5cm}
    Cross-Modal Attention:\\
    $Q = H^{(p)}W_Q$, $K=H^{(s)}W_K$, $V=H^{(s)}W_V$\\
    $C^{(s)} = \mathrm{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V$\\[0.2em]
    Gate:\\
    $G = \sigma(f_\mathrm{conv}([H^{(p)},C^{(s)}];W_g))$\\[0.2em]
    Fusion:\\
    $H_\mathrm{fused} = (1-G)\odot H^{(p)} + G \odot C^{(s)}$
    \end{minipage}
};

% Projection Head
\node (proj) [right=2.4cm of attn, draw, rounded corners, minimum width=2.3cm, minimum height=0.8cm, fill=gray!10] {Projection Head\\$z_i = f_\mathrm{proj}(H_\mathrm{fused})$};

% Latent manifold
\node (manifold) [right=2.3cm of proj, draw, ellipse, minimum width=4.1cm, minimum height=3.5cm, fill=green!7, label=below:{\footnotesize Dynamically Structured Manifold $\mathcal{Z}$}] {$\{z_i\}$ \\[0.4ex] Cluster centroids $\{\mu_k\}$};

% Decoder branch
\node (decoder) [below=1.6cm of proj, draw, rounded corners, minimum width=2.3cm, minimum height=0.8cm, fill=yellow!12] {Decoder\\$\hat{x}^{(p)}$};

% Losses
\node (loss_rec) [below=0.9cm of decoder, draw, cloud, cloud puffs=10, cloud ignores aspect, minimum width=2.0cm, minimum height=1.0cm, fill=red!8] {$L_\mathrm{rec}$};
\node (loss_cluster) [above=1.3cm of manifold, draw, cloud, cloud puffs=10, cloud ignores aspect, minimum width=2.0cm, minimum height=1.0cm, fill=cyan!10] {$L_\mathrm{cluster}$};
\node (loss_con) [right=1.3cm of manifold, draw, cloud, cloud puffs=10, cloud ignores aspect, minimum width=2.0cm, minimum height=1.0cm, fill=purple!7] {$L_\mathrm{con}$};

% Outputs
\node (out1) [right=2.1cm of loss_con] {Cluster\\Assignments $y$\\[0.2ex]\textit{(optionally:}\\[-1.2ex]Uncertainty $U$)};

% Connections: Inputs to encoders
\draw[->] (x_p) -- (enc_p);
\draw[->] (x_s) -- (enc_s);

% Encoders to attention
\draw[->] (enc_p) -- ++(0.5,0) |- (attn.west);
\draw[->] (enc_s) -- ++(0.5,0) |- (attn.west);

% Attention to projection
\draw[->] (attn) -- (proj);

% Projection to manifold
\draw[->] (proj) -- (manifold);

% Projection to decoder (for reconstruction)
\draw[->, dashed] (proj) -- (decoder);

% Decoder to rec loss
\draw[->, dashed] (decoder) -- (loss_rec);

% Feedback: rec loss to enc_p (optional, show as feedback)
\draw[->, dashed, bend right=40] (loss_rec) to (enc_p);

% Manifold to cluster loss
\draw[->] (manifold) -- (loss_cluster);

% Feedback: cluster loss to attention (optional, feedback)
\draw[->, dashed, bend left=18] (loss_cluster) to (attn);

% Manifold to contrastive loss
\draw[->] (manifold) -- (loss_con);

% Feedback: contrastive loss to attention (optional, feedback)
\draw[->, dashed, bend right=14] (loss_con) to (attn);

% Cluster assignment output
\draw[->] (manifold) -- (out1);

\end{tikzpicture}
}
\caption{Block diagram of the proposed Dynamically Structured Manifold Clustering (DSMC) framework. The architecture features parallel modality-specific encoders, a gated cross-modal attention fusion module, a projection head to latent embeddings, and a dynamically structured manifold $\mathcal{Z}$. Three losses—reconstruction ($L_\mathrm{rec}$), clustering ($L_\mathrm{cluster}$), and contrastive ($L_\mathrm{con}$)—cooperatively drive learning and dynamically mold the manifold structure for cluster assignments and uncertainty quantification.}
\end{figure*}

\begin{figure*}[ht]
\centering
\resizebox{\textwidth}{!}{%

\begin{tikzpicture}[
    node distance=2.2cm and 2.0cm,
    every node/.style={font=\footnotesize, align=center},
    >=latex,
    thick
]

% Inputs (layer 1)
\node (x_p) [draw, rounded corners, fill=orange!15] {Primary Modality \\ $x^{(p)}$};
\node (x_s) [below=of x_p, draw, rounded corners, fill=blue!15] {Secondary Modality \\ $x^{(s)}$};

% Encoders (layer 2)
\node (enc_p) [right=of x_p, draw, rounded corners, fill=orange!5] {Primary Encoder \\ $H^{(p)}$};
\node (enc_s) [right=of x_s, draw, rounded corners, fill=blue!5] {Secondary Encoder \\ $H^{(s)}$};

% Gated Cross-Modal Attention (center layer)
\node (attn) [right=2.5cm of $(enc_p)!0.5!(enc_s)$, draw, rounded corners, fill=purple!10, minimum width=4cm, minimum height=2.5cm] {Gated Cross-Modal Attention\\...equations...};

% Projection (layer 4)
\node (proj) [right=of attn, draw, rounded corners, fill=gray!10] {Projection Head \\ $z_i$};

% Decoder (below projection)
\node (decoder) [below=of proj, draw, rounded corners, fill=yellow!12] {Decoder \\ $\hat{x}^{(p)}$};

% Manifold (layer 5)
\node (manifold) [right=of proj, draw, ellipse, fill=green!7, minimum width=3.6cm, minimum height=2.6cm] {Manifold \\ $\mathcal{Z}$};

% Losses (above relevant nodes)
\node (loss_rec) [above=of decoder, draw, cloud, fill=red!8] {$L_\mathrm{rec}$};
\node (loss_cluster) [above=of manifold, draw, cloud, fill=cyan!10] {$L_\mathrm{cluster}$};
\node (loss_con) [right=of manifold, draw, cloud, fill=purple!7] {$L_\mathrm{con}$};

% Outputs
\node (out1) [right=of loss_con, align=center] {Cluster \\ Assignments};

% ARROWS
\draw[->] (x_p) -- (enc_p);
\draw[->] (x_s) -- (enc_s);
\draw[->] (enc_p) -- (attn);
\draw[->] (enc_s) -- (attn);

\draw[->] (attn) -- (proj);
\draw[->] (proj) -- (manifold);

\draw[->] (proj) -- (decoder);
\draw[->] (decoder) -- (loss_rec);

\draw[->] (manifold) -- (loss_cluster);
\draw[->] (manifold) -- (loss_con);
\draw[->] (manifold) -- (out1);

% Loss feedbacks
\draw[->, dashed] (loss_rec) -| (enc_p);
\draw[->, dashed] (loss_cluster) -| (attn);
\draw[->, dashed] (loss_con) -- ++(0.5,0) |- (attn);

\end{tikzpicture}
}
\caption{Block diagram of the proposed Dynamically Structured Manifold Clustering (DSMC) framework. The architecture features parallel modality-specific encoders, a gated cross-modal attention fusion module, a projection head to latent embeddings, and a dynamically structured manifold $\mathcal{Z}$. Three losses—reconstruction ($L_\mathrm{rec}$), clustering ($L_\mathrm{cluster}$), and contrastive ($L_\mathrm{con}$)—cooperatively drive learning and dynamically mold the manifold structure for cluster assignments and uncertainty quantification.}
\end{figure*}

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/overview_architecture.pdf} % Assuming figure is in 'figures' subdir
\caption{An overview of the proposed Dynamically Structured Manifold Clustering (DSMC) framework. The architecture learns an adaptively structured manifold through two key mechanisms: (1) a Gated Cross-Modal Attention module for dynamic modal fusion, and (2) a Contrastive-Augmented objective that enforces a cluster-friendly geometric structure on the fused latent embedding. The process dynamically shapes the manifold $\mathcal{Z}$.}
\label{fig:overview}
\end{figure}

\subsection{Adaptive Modal Fusion via Gated Cross-Modal Attention}
A pivotal challenge in multi-modal learning is the effective fusion of information from heterogeneous sources, avoiding simplistic concatenation or summation that may dilute critical modality-specific features or fail to capture dynamic interdependencies. To address this, we propose a Gated Cross-Modal Attention mechanism designed to learn adaptive control over the influence of the secondary modality (e.g., weather) on the primary modality (e.g., energy load).

Let $\mathbf{H}^{(p)} \in \mathbb{R}^{T' \times d_h}$ and $\mathbf{H}^{(s)} \in \mathbb{R}^{T' \times d_h}$ be the sequential hidden representations derived from the primary modality $\mathbf{x}^{(p)}$ and secondary modality $\mathbf{x}^{(s)}$, respectively, via modality-specific encoders (e.g., stacked 1D dilated convolutions). $T'$ is the sequence length after encoding and $d_h$ is the hidden dimension. First, we compute an attention-weighted context from the secondary modality, $\mathbf{C}^{(s)}$, which highlights features in $\mathbf{H}^{(s)}$ most relevant to $\mathbf{H}^{(p)}$ at each time step:
\begin{align}
\mathbf{Q} &= \mathbf{H}^{(p)} \mathbf{W}_Q, \quad \mathbf{K} = \mathbf{H}^{(s)} \mathbf{W}_K, \quad \mathbf{V} = \mathbf{H}^{(s)} \mathbf{W}_V \label{eq:qkv_matrices}\\
\mathbf{C}^{(s)} &= \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right)\mathbf{V} \label{eq:attention_context}
\end{align}
where $\mathbf{W}_Q, \mathbf{W}_K, \mathbf{W}_V \in \mathbb{R}^{d_h \times d_k}$ are learnable projection matrices, and $d_k$ is the dimension of keys and queries.
Subsequently, a learnable gating mechanism $\mathbf{G} \in \mathbb{R}^{T' \times d_h}$ is introduced to dynamically blend the primary representation $\mathbf{H}^{(p)}$ with the derived context $\mathbf{C}^{(s)}$. The gate $\mathbf{G}$ is computed based on both $\mathbf{H}^{(p)}$ and $\mathbf{C}^{(s)}$:
\begin{equation}
\mathbf{G} = \sigma(f_{\text{conv}}(\text{concat}[\mathbf{H}^{(p)}, \mathbf{C}^{(s)}]; \mathbf{W}_g)) \label{eq:gate_revised}
\end{equation}
where $f_{\text{conv}}(\cdot; \mathbf{W}_g)$ represents a 1D convolutional layer (e.g., kernel size 3, `same` padding, ReLU activation followed by a final convolution to $d_h$ channels) parameterized by $\mathbf{W}_g$, operating along the temporal dimension of the concatenated input. $\sigma(\cdot)$ is the sigmoid function, constraining gate values to $(0,1)$. The fused representation $\mathbf{H}_{\text{fused}} \in \mathbb{R}^{T' \times d_h}$ is then obtained as:
\begin{equation}
\mathbf{H}_{\text{fused}} = (1 - \mathbf{G}) \odot \mathbf{H}^{(p)} + \mathbf{G} \odot \mathbf{C}^{(s)} \label{eq:gated_fusion_revised}
\end{equation}
where $\odot$ denotes element-wise multiplication. This Gated Cross-Modal Attention allows $\mathbf{H}_{\text{fused}}$ to be a learned, temporally varying convex combination of the primary modality's representation and the attention-derived context from the secondary modality. Such a mechanism enables the model to adaptively emphasize or de-emphasize the secondary modality's influence at different time steps based on learned patterns, providing a more flexible and theoretically grounded fusion than static methods. This adaptivity is crucial for modeling time series where inter-modal relevance fluctuates, and the interpretability of $\mathbf{G}$ (as shown in Section V.C) allows for insights into these learned dynamic relationships.

\subsection{Manifold Structuring via Contrastive-Augmented Clustering Objective}
After obtaining a fused representation $\mathbf{H}_{\text{fused}}$, it is typically processed (e.g., flattened or globally pooled) and projected by a mapping $f_{\text{proj}}$ to yield the final embedding $\mathbf{z}_i = f_{\text{proj}}(\mathbf{H}_{\text{fused},i}) \in \mathbb{R}^d$. The second fundamental challenge is to structure the latent manifold $\mathcal{Z}$, populated by these embeddings $\{\mathbf{z}_i\}$, to be optimally separable into $K$ distinct clusters. To achieve this, DSMC augments a standard DEC-style clustering objective with a supervised contrastive loss, thereby providing robust structural constraints on the manifold's geometry.

The process commences by initializing $K$ cluster centroids $\{\boldsymbol{\mu}_k\}_{k=1}^K \subset \mathbb{R}^d$, often using K-means on initial embeddings. Soft cluster assignments $q_{ik}$, representing the probability of assigning embedding $\mathbf{z}_i$ to cluster $k$, are computed using the Student's t-distribution kernel as a similarity measure:
\begin{equation}
q_{ik} = \frac{(1 + \|\mathbf{z}_i - \boldsymbol{\mu}_k\|^2 / \alpha)^{-(\alpha+1)/2}}{\sum_{j=1}^K (1 + \|\mathbf{z}_i - \boldsymbol{\mu}_j\|^2 / \alpha)^{-(\alpha+1)/2}}
\label{eq:soft_assignment_revised}
\end{equation}
where $\alpha$ is the degrees of freedom of the t-distribution (set to 1 in our experiments).
The primary clustering loss, $\mathcal{L}_{\text{cluster}}$, refines these assignments and the embeddings by minimizing the Kullback-Leibler (KL) divergence between the distribution $\mathbf{Q} = [q_{ik}]$ and an auxiliary target distribution $\mathbf{P} = [p_{ik}]$:
\begin{equation}
\mathcal{L}_{\text{cluster}} = \text{KL}(\mathbf{P} \| \mathbf{Q}) = \sum_i \sum_k p_{ik} \log \frac{p_{ik}}{q_{ik}}
\label{eq:kl_loss_revised}
\end{equation}
The target distribution $\mathbf{P}$ is computed by sharpening the model's own high-confidence predictions, thereby providing a self-supervisory signal that encourages more decisive cluster assignments:
\begin{equation}
p_{ik} = \frac{q_{ik}^2 / \sum_{j=1}^N q_{jk}}{\sum_{k'=1}^K (q_{ik'}^2 / \sum_{j=1}^N q_{jk'})}
\label{eq:target_dist_revised}
\end{equation}
where $N$ is the total number of samples.

Crucially, to directly engineer a more discriminative geometry within $\mathcal{Z}$, we introduce the supervised contrastive loss $\mathcal{L}_{\text{con}}$ \cite{khosla2020supervised_contrastive}. This loss leverages the pseudo-labels derived from the target distribution $\mathbf{P}$ (e.g., $y_i^* = \arg\max_k p_{ik}$) to structure the embedding space. For an anchor sample $i$ within a mini-batch $\mathcal{B}$, the set of positive samples $\mathcal{P}(i) = \{j \in \mathcal{B} \setminus \{i\} \mid y_j^* = y_i^*\}$ comprises all other samples in the batch sharing the same pseudo-label as $i$. The contrastive loss is then defined as:
\begin{equation}
\mathcal{L}_{\text{con}} = \sum_{i \in \mathcal{B}} \frac{-1}{|\mathcal{P}(i)|} \sum_{p \in \mathcal{P}(i)} \log \frac{\exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_p) / \tau)}{\sum_{a \in \mathcal{A}(i)} \exp(\text{sim}(\mathbf{z}_i, \mathbf{z}_a) / \tau)}
\label{eq:contrastive_loss_revised}
\end{equation}
where $\mathcal{A}(i) = \mathcal{B} \setminus \{i\}$ is the set of all other samples in the batch (both positive and negative with respect to $i$'s pseudo-label class), $\text{sim}(\mathbf{u}, \mathbf{v}) = \mathbf{u}^T \mathbf{v} / (\|\mathbf{u}\| \|\mathbf{v}\|)$ is the cosine similarity, and $\tau > 0$ is a temperature hyperparameter. A small $\tau$ makes the loss focus on harder negatives.
The inclusion of $\mathcal{L}_{\text{con}}$ actively encourages increased cosine similarity (alignment) between embeddings of samples with the same pseudo-label, while simultaneously decreasing similarity between those with different pseudo-labels. This explicitly optimizes the manifold for a metric structure that improves intra-cluster compactness and inter-cluster separation, directly benefiting distance-based clustering quality and potentially improving metrics such as silhouette score and Davies-Bouldin index for the learned embeddings.

\subsection{Network Architecture and Training}
\subsubsection{Architectural and Implementation Details}
The DSMC framework employs parallel encoder streams for each modality. Each encoder consists of a stack of three 1D dilated convolutional layers with exponentially increasing dilation rates ($r=1, 2, 4$) and ReLU activations, designed to efficiently capture long-range temporal dependencies in time series data. The output of each encoder, $\mathbf{H}^{(p)}$ and $\mathbf{H}^{(s)}$, has $d_h=64$ channels. The Gated Cross-Modal Attention module uses projection matrices for $d_k=32$. The $f_{\text{conv}}$ in the gate (Eq. \ref{eq:gate_revised}) is a 1D convolution with kernel size 3, 64 filters, and ReLU, followed by another 1D convolution with kernel size 1 projecting to $d_h$ channels before the sigmoid. The fused representation $\mathbf{H}_{\text{fused}}$ is globally average-pooled along the time dimension and then passed through a dense layer to produce embeddings $\mathbf{z}_i \in \mathbb{R}^{10}$ (i.e., $d=10$). The decoder, used for $\mathcal{L}_{\text{rec}}$, symmetrically mirrors the primary modality's encoder using transposed 1D convolutions to reconstruct the input load shape.
For uncertainty quantification, Monte Carlo (MC) Dropout \cite{mc_dropout_gal} is employed with a dropout rate of $p_{dropout}=0.2$ applied after convolutional and dense layers during both training and inference. At inference time, $M=20$ stochastic forward passes are performed to obtain a distribution over soft cluster assignments for each sample. The entropy of the mean of this distribution serves as the uncertainty score. The temperature for the contrastive loss is $\tau=0.1$. The loss weights $\lambda=1.0$ and $\gamma=0.5$ were selected based on empirical evaluation on a validation set, aiming to balance the contributions of each loss term. The framework is implemented in TensorFlow 2.8.

\subsubsection{Training Algorithm}
The complete training procedure for DSMC is detailed in Algorithm \ref{alg:dsmc_training}. The process initiates with a pre-training phase to initialize the encoders and decoder by minimizing $\mathcal{L}_{\text{rec}}$ only, establishing a stable initial manifold. Subsequently, the full DSMC model is trained by jointly minimizing the composite loss $\mathcal{L}_{\text{total}}$ (Eq. \ref{eq:total_loss_revised}). During this joint optimization phase, the cluster centroids $\{\boldsymbol{\mu}_k\}$ are initialized using K-means on the embeddings from the pre-trained encoder. The target distribution $\mathbf{P}$ is updated periodically (e.g., every $\Delta$ epochs). The synergy between the loss components is critical: $\mathcal{L}_{\text{cluster}}$ iteratively refines pseudo-labels via $\mathbf{P}$, which $\mathcal{L}_{\text{con}}$ then utilizes to enforce a robust geometric structure on the latent space, enhancing cluster separability.

\begin{algorithm}[h!]
\caption{Dynamically Structured Manifold Clustering (DSMC)}
\label{alg:dsmc_training} % Changed label from alg:wfdec
\begin{algorithmic}[1]
\REQUIRE Primary modality data $\mathbf{X}^{(p)}$, secondary modality data $\mathbf{X}^{(s)}$, number of clusters $K$, loss weights $\lambda, \gamma$, pre-training epochs $E_{pre}$, clustering epochs $E_{cluster}$, target update interval $\Delta$.
\ENSURE Cluster assignments $\mathbf{y}$, latent embeddings $\mathbf{Z}$, uncertainty scores $\mathbf{U}$.

\STATE \textbf{Stage 1: Manifold Initialization (Pre-training)}
\STATE Initialize encoder parameters $\theta_{enc}^{(p)}, \theta_{enc}^{(s)}$, decoder $\theta_{dec}$.
\FOR{$epoch = 1$ to $E_{pre}$}
    \STATE For each batch, compute $\mathbf{H}^{(p)}, \mathbf{H}^{(s)}$, $\mathbf{H}_{\text{fused}}$, then $\mathbf{z}$.
    \STATE Reconstruct $\hat{\mathbf{x}}^{(p)}$ from $\mathbf{z}$ (or $\mathbf{H}_{\text{fused}}$ if decoder is structured so).
    \STATE Update $\theta_{enc}^{(p)}, \theta_{enc}^{(s)}, \theta_{dec}$ by minimizing reconstruction loss $\mathcal{L}_{\text{rec}}(\mathbf{x}^{(p)}, \hat{\mathbf{x}}^{(p)})$.
\ENDFOR

\STATE \textbf{Stage 2: Joint Manifold Structuring and Clustering}
\STATE Compute initial embeddings $\mathbf{Z}^{(0)}$ for all data using pre-trained encoders and fusion module.
\STATE Initialize cluster centroids $\{\boldsymbol{\mu}_k\}_{k=1}^K$ using K-means on $\mathbf{Z}^{(0)}$.
\STATE Let $y_{prev}$ store previous cluster assignments.
\FOR{$epoch = 1$ to $E_{cluster}$}
    \IF{$epoch \pmod \Delta == 0$ or $epoch == 1$}
        \STATE Compute soft assignments $\mathbf{Q}$ (Eq. \ref{eq:soft_assignment_revised}) and target distribution $\mathbf{P}$ (Eq. \ref{eq:target_dist_revised}) over all data.
        \STATE Assign $y_i = \arg\max_k q_{ik}$. If change in $y$ w.r.t $y_{prev}$ is below threshold $\delta_{tol}$ (e.g., 0.1\%), set convergence flag. Update $y_{prev} \leftarrow y$.
    \ENDIF
    \IF{convergence flag is set}
        \STATE \textbf{break}
    \ENDIF
    \STATE For each batch:
        \STATE Compute $\mathbf{z}_i$ for all samples in batch.
        \STATE Calculate $\mathcal{L}_{\text{rec}}$, $\mathcal{L}_{\text{cluster}}$ (using $\mathbf{P}$ from current interval), $\mathcal{L}_{\text{con}}$.
        \STATE Compute $\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{rec}} + \lambda\mathcal{L}_{\text{cluster}} + \gamma\mathcal{L}_{\text{con}}$.
        \STATE Update all learnable parameters ($\theta_{enc}^{(p)}, \theta_{enc}^{(s)}, \theta_{fuse}, \mathbf{W}_g, f_{\text{proj}}, \{\boldsymbol{\mu}_k\}$) by minimizing $\mathcal{L}_{\text{total}}$.
\ENDFOR

\STATE \textbf{Inference and Uncertainty Estimation}
\STATE For each sample $i$, perform $M$ stochastic forward passes (with MC Dropout enabled) to get $\{\mathbf{q}_i^{(m)}\}_{m=1}^M$.
\STATE Compute mean soft assignment $\bar{\mathbf{q}}_i = \frac{1}{M}\sum_{m=1}^M \mathbf{q}_i^{(m)}$.
\STATE Final cluster assignment $\mathbf{y}_i = \arg\max_k \bar{q}_{ik}$.
\STATE Compute uncertainty score $U_i = -\sum_{k=1}^K \bar{q}_{ik} \log_2 \bar{q}_{ik}$ (entropy of mean prediction).
\STATE Collect all $\mathbf{y}_i$ into $\mathbf{Y}$, $\mathbf{z}_i$ into $\mathbf{Z}$, and $U_i$ into $\mathbf{U}$.
\RETURN $\mathbf{Y}, \mathbf{Z}, \mathbf{U}$.
\end{algorithmic}
\end{algorithm}

\section{Experiments}
In this section, we conduct a series of comprehensive experiments to rigorously validate the effectiveness of our proposed Dynamically Structured Manifold Clustering (DSMC) framework on the task of household energy segmentation. We aim to answer: (1) Does DSMC significantly outperform a wide range of state-of-the-art traditional, uni-modal deep, and multi-modal clustering methods? (2) Are the proposed novel components—Gated Cross-Modal Attention and the Contrastive-Augmented objective—essential for its superior performance? (3) Does DSMC produce interpretable results that provide actionable insights into the relationship between energy consumption and weather? (4) How robust is the framework to hyperparameter variations and what are its computational characteristics?

\subsection{Experimental Setup}

\subsubsection{Dataset}
We evaluate DSMC on the publicly available Pecan Street dataset \cite{pecan_street_dataset}, a richly detailed repository of electricity consumption data from residential homes. Our experiments utilize a subset comprising 500 homes located in Austin, Texas, with data spanning a one-year period. For each home, we extract daily 24-hour load profiles (kWh consumed per hour), forming the primary modality $\mathbf{X}^{(p)} \in \mathbb{R}^{N_{samples} \times 24 \times 1}$. Corresponding hourly weather data (ambient temperature and humidity) from a nearby weather station serves as the secondary modality $\mathbf{X}^{(s)} \in \mathbb{R}^{N_{samples} \times 24 \times 2}$. Both modalities are normalized to the range $[0, 1]$ independently. For evaluation, we leverage ground-truth household labels derived from a domain expert-driven segmentation study conducted on a similar subset of this dataset \cite{pecan_street_expert_study_placeholder}. This study identified $K=5$ distinct consumption archetypes (e.g., "Low Usage", "Morning Peakers", "Afternoon Peakers", "Evening Peakers", "Night Owls") based on qualitative and quantitative analysis of load shapes and household characteristics.
\textit{(Note to authors: Replace \cite{pecan_street_expert_study_placeholder} with the actual citation if available, or elaborate slightly on the expert criteria if no direct citation exists, e.g., "based on visual inspection of load shapes and statistical properties like peak timing and overall consumption by domain experts.")}

\subsubsection{Evaluation Metrics}
We employ three standard external validation metrics to assess clustering performance: Clustering Accuracy (ACC), Normalized Mutual Information (NMI), and Adjusted Rand Index (ARI). For all metrics, higher values indicate superior clustering performance, with 1.0 representing a perfect match with ground-truth labels. ACC is computed after finding the optimal mapping between predicted clusters and true labels using the Hungarian algorithm.

\subsubsection{Compared Methods}
We benchmark DSMC against a comprehensive and categorized set of baseline methods:
\begin{itemize}
    \item \textbf{Traditional Methods:} K-means applied directly to the flattened 24-hour load profiles.
    \item \textbf{Uni-modal Deep Methods:}
        \begin{itemize}
            \item \textit{AE + K-means:} An autoencoder trained on load data to learn embeddings, followed by K-means on these embeddings.
            \item \textit{DEC \cite{deep_embedding_clustering_xie}:} Deep Embedded Clustering trained solely on load data.
        \end{itemize}
    \item \textbf{Multi-modal Baselines:}
        \begin{itemize}
            \item \textit{Concat-DEC:} A baseline where flattened load and weather data are concatenated channel-wise before being input to a standard DEC model with an AE backbone.
            \item \textit{MM-VAE:} A Multi-Modal Variational Autoencoder \cite{mmvae_sutter} adapted for clustering, learning a joint latent space over load and weather data. Clustering is performed on the mean of the inferred latent variables.
            \item \textit{Late-Fusion-DEC:} Separate DEC models are trained for each modality (load and weather). Their final soft assignment distributions ($q_{ik}$) are averaged, and cluster assignments are derived from this averaged distribution.
        \end{itemize}
    \item \textbf{DSMC Ablations:} To assess the contribution of DSMC's key components:
        \begin{itemize}
            \item \textit{DSMC w/o Gate:} Replaces the Gated Cross-Modal Attention (Eq. \ref{eq:gated_fusion_revised}) with simple additive fusion of $\mathbf{H}^{(p)}$ and $\mathbf{C}^{(s)}$.
            \item \textit{DSMC w/o Contrastive:} Removes the contrastive loss term $\mathcal{L}_{\text{con}}$ from the total objective (i.e., $\gamma=0$).
        \end{itemize}
\end{itemize}
All deep learning models share a similar encoder architecture (dilated convolutions) where applicable for fair comparison.

\subsubsection{Implementation Details}
All deep learning models are implemented using TensorFlow 2.8 and trained on a single NVIDIA A100 GPU. The Adam optimizer \cite{kingma2014adam} is used with an initial learning rate of $1 \times 10^{-4}$, which is decayed if validation loss plateaus. For DSMC, the loss weights are $\lambda=1.0$ and $\gamma=0.5$, and the contrastive temperature $\tau=0.1$. These hyperparameters were selected based on preliminary experiments on a small, held-out validation portion (10\%) of the training data, aiming for robust performance and balanced loss contributions. All models undergo a pre-training phase for 50 epochs (AE-based models and DSMC's $\mathcal{L}_{\text{rec}}$ phase) and a joint clustering optimization phase for up to 200 epochs, with early stopping if the convergence criterion in Algorithm \ref{alg:dsmc_training} (change in cluster assignments $<0.1\%$ over 10 consecutive target updates) is met. All reported results are averaged over 10 independent runs with different random seeds to account for initialization stochasticity.

\subsection{Quantitative Results}

\begin{table}[h!]
\centering
\caption{Clustering Performance Comparison on the Pecan Street Dataset. Mean values over 10 runs are reported. Standard deviations were typically below 0.015 for ACC/NMI/ARI for deep models. Best results are highlighted in bold.}
\label{tab:main_results}
\resizebox{\columnwidth}{!}{%
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Method} & \textbf{ACC} & \textbf{NMI} & \textbf{ARI} \\ \midrule
\textit{Traditional Methods} & & & \\
K-means (on load profiles) & 0.453 & 0.381 & 0.298 \\ \midrule
\textit{Uni-modal Deep Methods (on load data)} & & & \\
AE + K-means & 0.589 & 0.512 & 0.421 \\
DEC & 0.652 & 0.598 & 0.503 \\ \midrule
\textit{Multi-modal Baselines} & & & \\
Concat-DEC & 0.681 & 0.624 & 0.545 \\
MM-VAE & 0.702 & 0.645 & 0.570 \\
Late-Fusion-DEC & 0.665 & 0.609 & 0.521 \\ \midrule
\textit{DSMC Ablations} & & & \\
DSMC w/o Gate & 0.735 & 0.688 & 0.612 \\
DSMC w/o Contrastive & 0.751 & 0.703 & 0.635 \\ \midrule
\textbf{DSMC (Ours)} & \textbf{0.824} & \textbf{0.765} & \textbf{0.718} \\ \bottomrule
\end{tabular}%
}
\end{table}

The primary quantitative results are presented in Table \ref{tab:main_results}. Our proposed DSMC framework demonstrates a clear and significant performance advantage across all three evaluation metrics (ACC, NMI, ARI) compared to all baseline methods. Key observations include:
\begin{enumerate}
    \item Deep learning methods substantially outperform the traditional K-means baseline, underscoring the value of learned feature representations for complex time series data.
    \item Uni-modal deep methods (AE + K-means, DEC) show considerable improvement over K-means, with DEC achieving better results due to its joint optimization.
    \item Multi-modal methods, even relatively simple ones like Concat-DEC, consistently outperform their uni-modal counterparts. This confirms the hypothesis that incorporating the secondary weather data stream is beneficial for energy consumption clustering. The more sophisticated MM-VAE achieves the best performance among these generic multi-modal baselines.
    \item The full DSMC model achieves a substantial performance gain over the strongest multi-modal baselines. For instance, DSMC surpasses MM-VAE by approximately 12.2\% in ACC, 12.0\% in NMI, and 14.8\% in ARI. This highlights the efficacy of DSMC's specialized Gated Cross-Modal Attention and Contrastive-Augmented objective compared to simpler fusion strategies or generic latent variable models.
\end{enumerate}
These results strongly suggest that DSMC's approach to adaptively fusing modalities and explicitly structuring the latent manifold leads to more accurate and meaningful clusterings of multi-modal time series.

\subsection{Ablation Study}
To rigorously validate the contribution of DSMC's core novel components, we analyze the performance of its ablated versions, as reported in Table \ref{tab:main_results}.

\subsubsection{Effect of Gated Cross-Modal Attention}
Comparing the full DSMC model with "DSMC w/o Gate" (where the gating mechanism is replaced by simple additive fusion of $\mathbf{H}^{(p)}$ and $\mathbf{C}^{(s)}$) reveals the crucial role of our adaptive fusion mechanism. The absence of the learned gate results in a significant performance degradation across all metrics: an absolute drop of 8.9\% in ACC (0.824 to 0.735), 7.7\% in NMI (0.765 to 0.688), and 10.6\% in ARI (0.718 to 0.612). This substantial difference confirms our design principle that a learnable gate, capable of dynamically regulating the influence of the secondary modality based on context (as per Eq. \ref{eq:gated_fusion_revised}), is markedly superior to a static or non-adaptive fusion approach for these heterogeneous time series.

\subsubsection{Effect of Contrastive-Augmented Objective}
Similarly, comparing DSMC with "DSMC w/o Contrastive" (where $\mathcal{L}_{\text{con}}$ is removed, i.e., $\gamma=0$) highlights the importance of explicitly structuring the latent manifold. Removing the contrastive loss term leads to a clear performance drop: 7.3\% in ACC (0.824 to 0.751), 6.2\% in NMI (0.765 to 0.703), and 8.3\% in ARI (0.718 to 0.635). This demonstrates that while the standard DEC-style clustering loss ($\mathcal{L}_{\text{cluster}}$) provides a good clustering signal by iteratively refining assignments, augmenting it with a contrastive objective that actively organizes the manifold's geometry (by pulling same-pseudo-label embeddings together and pushing others apart) is crucial for learning a more discriminative and well-separated representation space.

These ablation results provide strong empirical evidence for the individual and combined utility of the Gated Cross-Modal Attention and the Contrastive-Augmented objective within the DSMC framework.

\subsection{Qualitative Analysis and Visualization}

\begin{figure}[h!]
\centering
\subfigure[MM-VAE (Baseline Embeddings)]{
    \includegraphics[width=0.48\columnwidth]{figures/tsne_concat.pdf} % Assuming this was the intended baseline vis
    \label{fig:tsne_mmvae}
}
\hfill % or \hspace{0.02\columnwidth}
\subfigure[DSMC (Our Embeddings)]{
    \includegraphics[width=0.48\columnwidth]{figures/tsne_dsmc.pdf}
    \label{fig:tsne_dsmc}
}
\caption{t-SNE visualization of the learned latent embeddings $\mathbf{z}_i$ for 500 samples from the Pecan Street dataset, colored by ground-truth cluster labels. (a) Embeddings from the strongest baseline, MM-VAE. (b) Embeddings from our full DSMC model. DSMC produces visibly more compact, well-separated, and coherently structured clusters.}
\label{fig:tsne}
\end{figure}

\subsubsection{Latent Space Visualization}
To qualitatively assess the structure of the learned manifold, Figure \ref{fig:tsne} presents t-SNE \cite{van2008visualizing} visualizations of the 10-dimensional latent embeddings $\mathbf{z}_i$ produced by the strongest baseline (MM-VAE) and our full DSMC model. The embeddings are colored according to their ground-truth cluster labels. As depicted in Figure \ref{fig:tsne_dsmc}, the embeddings generated by DSMC form visibly more compact and well-separated clusters compared to those from MM-VAE (Figure \ref{fig:tsne_mmvae}), which show more overlap and less distinct boundaries between certain groups. This visual evidence aligns with the quantitative improvements reported in Table \ref{tab:main_results} and qualitatively supports the hypothesis that the Contrastive-Augmented objective, in conjunction with adaptive fusion, successfully enforces a more cluster-friendly geometry on the learned manifold.

\subsubsection{Attention Gate Visualization and Interpretability}
A key advantage of the Gated Cross-Modal Attention mechanism is its potential for interpretability. To demonstrate this, we visualize the learned gate values $\mathbf{G}_t$ (from Eq. \ref{eq:gate_revised}, averaged over the $d_h$ feature channels for visualization) for a representative household belonging to the "Afternoon Peakers" cluster during a hot summer day. This cluster typically exhibits increased energy consumption during afternoon hours, often due to air conditioning usage. Figure \ref{fig:attention} plots these gate values alongside the corresponding ambient temperature. The gate values are notably higher during the afternoon hours (approximately 1 PM - 5 PM), coinciding precisely with the peak in ambient temperature. This indicates that the DSMC model has learned to dynamically increase the influence of the weather modality (specifically temperature) on the fused representation during the times of day when it is most relevant to this household's consumption pattern (likely driving air conditioning load). This adaptive weighting, learned directly from data, provides a powerful and interpretable insight into the dynamic inter-modal relationships captured by DSMC.

\begin{figure}[h!]
\centering
\includegraphics[width=0.9\columnwidth]{figures/attention_gate.pdf} % Assuming figure is in 'figures' subdir
\caption{Visualization of the learned gate values (temporal average of $\mathbf{G}_t$ from Eq. \ref{eq:gate_revised}, shown in blue) from the Gated Cross-Modal Attention mechanism for a representative "Afternoon Peaker" household on a hot summer day. The gate values are highest during the afternoon, aligning with the peak in ambient temperature (red), demonstrating that the model learns to adaptively increase the influence of weather data when it is most relevant to the energy consumption pattern.}
\label{fig:attention}
\end{figure}

\subsection{Parameter Sensitivity, Error Analysis, and Computational Cost}
\subsubsection{Sensitivity to Hyperparameters}
To evaluate the robustness of DSMC, we analyzed its sensitivity to the key loss weight hyperparameters, $\lambda$ (for $\mathcal{L}_{\text{cluster}}$) and $\gamma$ (for $\mathcal{L}_{\text{con}}$). Figure \ref{fig:sensitivity} illustrates the clustering accuracy (ACC) as these parameters are varied. The results indicate that DSMC's performance is relatively stable across a reasonable range for both hyperparameters (e.g., $\lambda \in [0.5, 5.0]$ and $\gamma \in [0.1, 1.0]$ when the other is fixed at its default). While optimal performance is achieved around the selected values ($\lambda=1.0, \gamma=0.5$), the model is not unduly sensitive to precise tuning, suggesting its robustness for practical applications. This stability reduces the burden of extensive hyperparameter optimization.

\begin{figure}[h!]
\centering
\includegraphics[width=0.9\columnwidth]{figures/sensitivity.pdf} % Assuming figure is in 'figures' subdir
\caption{Sensitivity analysis of DSMC's clustering performance (ACC) with respect to the loss weights $\lambda$ (for $\mathcal{L}_{cluster}$) and $\gamma$ (for $\mathcal{L}_{con}$). One parameter is varied while the other is kept at its default value (1.0 for $\lambda$, 0.5 for $\gamma$). The model exhibits stable performance across a practical range of values for both hyperparameters.}
\label{fig:sensitivity}
\end{figure}

\subsubsection{Error Analysis and Limitations}
To provide a balanced perspective, we conducted an error analysis. Figure \ref{fig:failure_case} shows the daily load profile of a household that was frequently misclassified by DSMC. This household exhibits highly erratic and inconsistent consumption patterns from day to day, lacking a clear, discernible daily archetype. Such patterns are likely influenced by factors not captured by our current model's input modalities (load and weather), such as irregular work-from-home schedules, frequent resident travel, or non-routine appliance usage. Notably, the uncertainty score (Section III.C.2) assigned by DSMC to this household's cluster predictions was consistently high (mean entropy $U > 0.85$ across its daily profiles, where max entropy for K=5 is $\log_2 5 \approx 2.32$), correctly flagging its predictions as unreliable. This suggests that while DSMC is effective for households with discernible patterns driven by load history and weather, its primary limitation lies in modeling highly stochastic behavior or behavior driven by significant latent variables beyond the provided modalities. The uncertainty quantification, however, provides a mechanism to identify such cases.

\begin{figure}[h!]
\centering
\includegraphics[width=0.9\columnwidth]{figures/failure_case.pdf} % Assuming figure is in 'figures' subdir
\caption{Example of a challenging case for DSMC: daily load profiles (grey lines) and mean profile (red) for a household frequently misclassified. The consumption pattern is highly erratic and lacks consistent daily structure. The model correctly assigned a high uncertainty score to predictions for this sample, indicating low confidence.}
\label{fig:failure_case}
\end{figure}

\subsubsection{Computational Cost}
The DSMC framework incorporates several advanced components, including cross-modal attention, gating networks, and contrastive loss computations, which add to its computational complexity compared to simpler baselines like DEC or Concat-DEC. The per-epoch training time for DSMC on the Pecan Street dataset (500 homes, 1 year of daily profiles) was approximately 1.5-2.0 times that of Concat-DEC, primarily due to the attention mechanism and the pairwise similarity calculations in $\mathcal{L}_{\text{con}}$. However, with $E_{cluster}$ typically around 100-150 epochs due to early stopping, the total training time remained manageable (e.g., 2-3 hours on an NVIDIA A100). Inference time per sample is only marginally higher than a standard multi-modal autoencoder, as MC Dropout (with $M=20$) is the main factor for multiple forward passes if uncertainty is required; a single forward pass for point estimates is very fast. The performance gains achieved are substantial, justifying the moderate increase in computational resources for many applications.

\section{Conclusion and Future Work}
In this paper, we introduced Dynamically Structured Manifold Clustering (DSMC), a novel end-to-end framework meticulously designed for multi-modal time series clustering. By reformulating the clustering task as a problem of learning an adaptively structured latent manifold, DSMC makes several significant methodological contributions. We proposed a Gated Cross-Modal Attention mechanism that enables dynamic and interpretable fusion of heterogeneous time series, allowing the model, for instance, to learn the time-varying influence of weather on energy consumption patterns. Furthermore, we designed an innovative Contrastive-Augmented clustering objective that synergistically combines DEC-style iterative refinement with a supervised contrastive loss. This objective leverages self-generated pseudo-labels from the fused multi-modal representation to explicitly enforce a geometrically robust and well-separated structure on the learned manifold. The integration of MC Dropout also provides valuable uncertainty estimates for the clustering assignments.

Our comprehensive experiments on a real-world household energy consumption dataset demonstrated that DSMC achieves state-of-the-art performance, significantly outperforming a wide array of traditional, uni-modal deep, and existing multi-modal clustering baselines across standard evaluation metrics. The ablation studies rigorously validated that both the Gated Cross-Modal Attention and the Contrastive-Augmented objective are critical to DSMC's success, each contributing substantially to the overall performance. Moreover, qualitative analyses, including latent space visualizations and attention gate interpretations, confirmed the model's ability to produce more coherent clusters and offer interpretable insights into the complex dynamics between modalities, such as weather and energy consumption.

For future work, several promising research avenues emerge. The modular nature of the DSMC framework makes it amenable to extension with additional data modalities. As our error analysis indicated, some consumption patterns are driven by factors beyond daily load shapes and ambient weather; integrating data such as household demographics, appliance-level sub-metering, occupant schedules, or even textual information about household events could further improve segmentation accuracy and yield deeper behavioral insights. Another pertinent direction is the exploration of methods for automatically determining the optimal number of clusters ($K$), potentially by incorporating non-parametric Bayesian approaches or information-theoretic criteria into the DSMC objective. Investigating alternative contrastive learning strategies, such as those robust to noisy pseudo-labels, could also enhance performance. Finally, while developed and validated in the context of energy segmentation, the DSMC paradigm is general. Applying and adapting our framework to other multi-modal time series domains—such as clinical medicine (e.g., fusing physiological signals with electronic health records), autonomous driving (e.g., fusing LiDAR, camera, and RADAR data for scene understanding), or finance (e.g., fusing market data with news sentiment for asset clustering)—presents an exciting and potentially impactful trajectory for future research.


\section*{Acknowledgment}
The authors would like to thank... (To be completed by authors)
% This work was supported in part by [Funding Agency] under Grant [Grant Number].

% Placeholder for actual bibliography file
\bibliographystyle{IEEEtran}
\bibliography{references} 
% For the example, I'll use the bibitems from the original


\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author1.jpg}}]{Author Name}
% Biography to be completed later
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author2.jpg}}]{Second Author}
% Biography to be completed later
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author3.jpg}}]{Third Author}
% Biography to be completed later
\end{IEEEbiography}

\end{document}